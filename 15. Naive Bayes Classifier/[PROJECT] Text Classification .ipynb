{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GOAL:-**\n",
    "- 1. Perform Test Classification using Multinomial Naive Bayes(already implemented in sklearn).\n",
    "- 2. Implement Naive Bayes on your own from scratch for text classification. \n",
    "- 3. Compare Results of your implementation of Naive Bayes with one in Sklearn.\n",
    "- The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date.\n",
    "\n",
    "https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n"
     ]
    }
   ],
   "source": [
    "st = [1,2,3,4]\n",
    "print(type(st))\n",
    "print(dir(st))#gives all methods of list of python to print it prettier\n",
    "# we uses pprint function\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__',\n",
      " '__class__',\n",
      " '__contains__',\n",
      " '__delattr__',\n",
      " '__delitem__',\n",
      " '__dir__',\n",
      " '__doc__',\n",
      " '__eq__',\n",
      " '__format__',\n",
      " '__ge__',\n",
      " '__getattribute__',\n",
      " '__getitem__',\n",
      " '__gt__',\n",
      " '__hash__',\n",
      " '__iadd__',\n",
      " '__imul__',\n",
      " '__init__',\n",
      " '__init_subclass__',\n",
      " '__iter__',\n",
      " '__le__',\n",
      " '__len__',\n",
      " '__lt__',\n",
      " '__mul__',\n",
      " '__ne__',\n",
      " '__new__',\n",
      " '__reduce__',\n",
      " '__reduce_ex__',\n",
      " '__repr__',\n",
      " '__reversed__',\n",
      " '__rmul__',\n",
      " '__setattr__',\n",
      " '__setitem__',\n",
      " '__sizeof__',\n",
      " '__str__',\n",
      " '__subclasshook__',\n",
      " 'append',\n",
      " 'clear',\n",
      " 'copy',\n",
      " 'count',\n",
      " 'extend',\n",
      " 'index',\n",
      " 'insert',\n",
      " 'pop',\n",
      " 'remove',\n",
      " 'reverse',\n",
      " 'sort']\n"
     ]
    }
   ],
   "source": [
    "pprint(dir(st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "pprint(len(list(newsgroups_train.target_names))) # 20 category\n",
    "pprint(list(newsgroups_train.target_names)) # names of categories\n",
    "# task is a classifier on given documents into these given categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(newsgroups_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the given data into the form of X[] and Y[]\n",
    "were X[] will contain name of features(words) and Y[] categories\n",
    "1. Create Dictionary of words in document as key and frequency as value\n",
    "like w1 -> freq\n",
    "     w2 -> freq....\n",
    "there will be very few words with maximum no. of frequency.\n",
    "we will also filter words with small frequency, before adding this words\n",
    "to the dictionary we need to remove the \"STOPWORDS\"\n",
    "then pick top K words because all words wont be having same frequencies.\n",
    "1. Go through all documents\n",
    "2. within the doc. go through all words\n",
    "3. ignore the word if its a stopword\n",
    "4. add the word in dictionary if not already present\n",
    "5. else increase the frequency\n",
    "6. Choose top K word as features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords from https://gist.github.com/sebleier/554280\n",
    "stop_words =[\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\",\n",
    "             \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\"\n",
    "             , \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\",\n",
    "             \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\",\n",
    "             \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\",\n",
    "             \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\",\n",
    "             \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\",\n",
    "             \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n",
    "             \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \n",
    "             \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \n",
    "             \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \n",
    "             \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \n",
    "             \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \n",
    "             \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\",\n",
    "             \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\",\n",
    "             \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating X[] as a list of tuple where first element of tuple is name of\n",
    "document and text in document\n",
    "Y[] as Category\n",
    "\"\"\"\n",
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"./20newsgroup Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Datasets']\n"
     ]
    }
   ],
   "source": [
    "pprint(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "path = \"./20newsgroup Dataset/Datasets/\"\n",
    "pprint(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in os.listdir(path): #\"./20newsgroup Dataset/Datasets/\"\n",
    "    for documents in os.listdir(path+category): #\"./20newsgroup Dataset/Datasets/alt.atheism\"\n",
    "        with open(path+category+'/'+documents,'r') as f: #\"./20newsgroup Dataset/Datasets/alt.atheism/49960\"\n",
    "            X.append((documents,f.read()))\n",
    "            Y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "('49960',\n",
      " 'Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:49960 alt.atheism.moderated:713 '\n",
      " 'news.answers:7054 alt.answers:126\\n'\n",
      " 'Path: '\n",
      " 'cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!bb3.andrew.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!magnus.acs.ohio-state.edu!usenet.ins.cwru.edu!agate!spool.mu.edu!uunet!pipex!ibmpcug!mantis!mathew\\n'\n",
      " 'From: mathew <mathew@mantis.co.uk>\\n'\n",
      " 'Newsgroups: alt.atheism,alt.atheism.moderated,news.answers,alt.answers\\n'\n",
      " 'Subject: Alt.Atheism FAQ: Atheist Resources\\n'\n",
      " 'Summary: Books, addresses, music -- anything related to atheism\\n'\n",
      " 'Keywords: FAQ, atheism, books, music, fiction, addresses, contacts\\n'\n",
      " 'Message-ID: <19930329115719@mantis.co.uk>\\n'\n",
      " 'Date: Mon, 29 Mar 1993 11:57:19 GMT\\n'\n",
      " 'Expires: Thu, 29 Apr 1993 11:57:19 GMT\\n'\n",
      " 'Followup-To: alt.atheism\\n'\n",
      " 'Distribution: world\\n'\n",
      " 'Organization: Mantis Consultants, Cambridge. UK.\\n'\n",
      " 'Approved: news-answers-request@mit.edu\\n'\n",
      " 'Supersedes: <19930301143317@mantis.co.uk>\\n'\n",
      " 'Lines: 290\\n'\n",
      " '\\n'\n",
      " 'Archive-name: atheism/resources\\n'\n",
      " 'Alt-atheism-archive-name: resources\\n'\n",
      " 'Last-modified: 11 December 1992\\n'\n",
      " 'Version: 1.0\\n'\n",
      " '\\n'\n",
      " '                              Atheist Resources\\n'\n",
      " '\\n'\n",
      " '                      Addresses of Atheist Organizations\\n'\n",
      " '\\n'\n",
      " '                                     USA\\n'\n",
      " '\\n'\n",
      " 'FREEDOM FROM RELIGION FOUNDATION\\n'\n",
      " '\\n'\n",
      " 'Darwin fish bumper stickers and assorted other atheist paraphernalia are\\n'\n",
      " 'available from the Freedom From Religion Foundation in the US.\\n'\n",
      " '\\n'\n",
      " 'Write to:  FFRF, P.O. Box 750, Madison, WI 53701.\\n'\n",
      " 'Telephone: (608) 256-8900\\n'\n",
      " '\\n'\n",
      " 'EVOLUTION DESIGNS\\n'\n",
      " '\\n'\n",
      " 'Evolution Designs sell the \"Darwin fish\".  It\\'s a fish symbol, like the '\n",
      " 'ones\\n'\n",
      " 'Christians stick on their cars, but with feet and the word \"Darwin\" written\\n'\n",
      " 'inside.  The deluxe moulded 3D plastic fish is $4.95 postpaid in the US.\\n'\n",
      " '\\n'\n",
      " 'Write to:  Evolution Designs, 7119 Laurel Canyon #4, North Hollywood,\\n'\n",
      " '           CA 91605.\\n'\n",
      " '\\n'\n",
      " 'People in the San Francisco Bay area can get Darwin Fish from Lynn Gold --\\n'\n",
      " 'try mailing <figmo@netcom.com>.  For net people who go to Lynn directly, '\n",
      " 'the\\n'\n",
      " 'price is $4.95 per fish.\\n'\n",
      " '\\n'\n",
      " 'AMERICAN ATHEIST PRESS\\n'\n",
      " '\\n'\n",
      " 'AAP publish various atheist books -- critiques of the Bible, lists of\\n'\n",
      " 'Biblical contradictions, and so on.  One such book is:\\n'\n",
      " '\\n'\n",
      " '\"The Bible Handbook\" by W.P. Ball and G.W. Foote.  American Atheist Press.\\n'\n",
      " '372 pp.  ISBN 0-910309-26-4, 2nd edition, 1986.  Bible contradictions,\\n'\n",
      " 'absurdities, atrocities, immoralities... contains Ball, Foote: \"The Bible\\n'\n",
      " 'Contradicts Itself\", AAP.  Based on the King James version of the Bible.\\n'\n",
      " '\\n'\n",
      " 'Write to:  American Atheist Press, P.O. Box 140195, Austin, TX 78714-0195.\\n'\n",
      " '      or:  7215 Cameron Road, Austin, TX 78752-2973.\\n'\n",
      " 'Telephone: (512) 458-1244\\n'\n",
      " 'Fax:       (512) 467-9525\\n'\n",
      " '\\n'\n",
      " 'PROMETHEUS BOOKS\\n'\n",
      " '\\n'\n",
      " 'Sell books including Haught\\'s \"Holy Horrors\" (see below).\\n'\n",
      " '\\n'\n",
      " 'Write to:  700 East Amherst Street, Buffalo, New York 14215.\\n'\n",
      " 'Telephone: (716) 837-2475.\\n'\n",
      " '\\n'\n",
      " 'An alternate address (which may be newer or older) is:\\n'\n",
      " 'Prometheus Books, 59 Glenn Drive, Buffalo, NY 14228-2197.\\n'\n",
      " '\\n'\n",
      " 'AFRICAN-AMERICANS FOR HUMANISM\\n'\n",
      " '\\n'\n",
      " 'An organization promoting black secular humanism and uncovering the history '\n",
      " 'of\\n'\n",
      " 'black freethought.  They publish a quarterly newsletter, AAH EXAMINER.\\n'\n",
      " '\\n'\n",
      " 'Write to:  Norm R. Allen, Jr., African Americans for Humanism, P.O. Box '\n",
      " '664,\\n'\n",
      " '           Buffalo, NY 14226.\\n'\n",
      " '\\n'\n",
      " '                                United Kingdom\\n'\n",
      " '\\n'\n",
      " 'Rationalist Press Association          National Secular Society\\n'\n",
      " '88 Islington High Street               702 Holloway Road\\n'\n",
      " 'London N1 8EW                          London N19 3NL\\n'\n",
      " '071 226 7251                           071 272 1266\\n'\n",
      " '\\n'\n",
      " 'British Humanist Association           South Place Ethical Society\\n'\n",
      " \"14 Lamb's Conduit Passage              Conway Hall\\n\"\n",
      " 'London WC1R 4RH                        Red Lion Square\\n'\n",
      " '071 430 0908                           London WC1R 4RL\\n'\n",
      " 'fax 071 430 1271                       071 831 7723\\n'\n",
      " '\\n'\n",
      " 'The National Secular Society publish \"The Freethinker\", a monthly magazine\\n'\n",
      " 'founded in 1881.\\n'\n",
      " '\\n'\n",
      " '                                   Germany\\n'\n",
      " '\\n'\n",
      " 'IBKA e.V.\\n'\n",
      " 'Internationaler Bund der Konfessionslosen und Atheisten\\n'\n",
      " 'Postfach 880, D-1000 Berlin 41. Germany.\\n'\n",
      " '\\n'\n",
      " 'IBKA publish a journal:\\n'\n",
      " 'MIZ. (Materialien und Informationen zur Zeit. Politisches\\n'\n",
      " 'Journal der Konfessionslosesn und Atheisten. Hrsg. IBKA e.V.)\\n'\n",
      " 'MIZ-Vertrieb, Postfach 880, D-1000 Berlin 41. Germany.\\n'\n",
      " '\\n'\n",
      " 'For atheist books, write to:\\n'\n",
      " '\\n'\n",
      " 'IBDK, Internationaler B\"ucherdienst der Konfessionslosen\\n'\n",
      " 'Postfach 3005, D-3000 Hannover 1. Germany.\\n'\n",
      " 'Telephone: 0511/211216\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '                               Books -- Fiction\\n'\n",
      " '\\n'\n",
      " 'THOMAS M. DISCH\\n'\n",
      " '\\n'\n",
      " '\"The Santa Claus Compromise\"\\n'\n",
      " 'Short story.  The ultimate proof that Santa exists.  All characters and \\n'\n",
      " 'events are fictitious.  Any similarity to living or dead gods -- uh, '\n",
      " 'well...\\n'\n",
      " '\\n'\n",
      " 'WALTER M. MILLER, JR\\n'\n",
      " '\\n'\n",
      " '\"A Canticle for Leibowitz\"\\n'\n",
      " 'One gem in this post atomic doomsday novel is the monks who spent their '\n",
      " 'lives\\n'\n",
      " 'copying blueprints from \"Saint Leibowitz\", filling the sheets of paper with\\n'\n",
      " 'ink and leaving white lines and letters.\\n'\n",
      " '\\n'\n",
      " 'EDGAR PANGBORN\\n'\n",
      " '\\n'\n",
      " '\"Davy\"\\n'\n",
      " 'Post atomic doomsday novel set in clerical states.  The church, for '\n",
      " 'example,\\n'\n",
      " 'forbids that anyone \"produce, describe or use any substance containing...\\n'\n",
      " 'atoms\". \\n'\n",
      " '\\n'\n",
      " 'PHILIP K. DICK\\n'\n",
      " '\\n'\n",
      " 'Philip K. Dick Dick wrote many philosophical and thought-provoking short \\n'\n",
      " 'stories and novels.  His stories are bizarre at times, but very '\n",
      " 'approachable.\\n'\n",
      " 'He wrote mainly SF, but he wrote about people, truth and religion rather '\n",
      " 'than\\n'\n",
      " 'technology.  Although he often believed that he had met some sort of God, '\n",
      " 'he\\n'\n",
      " 'remained sceptical.  Amongst his novels, the following are of some '\n",
      " 'relevance:\\n'\n",
      " '\\n'\n",
      " '\"Galactic Pot-Healer\"\\n'\n",
      " 'A fallible alien deity summons a group of Earth craftsmen and women to a\\n'\n",
      " 'remote planet to raise a giant cathedral from beneath the oceans.  When the\\n'\n",
      " 'deity begins to demand faith from the earthers, pot-healer Joe Fernwright '\n",
      " 'is\\n'\n",
      " 'unable to comply.  A polished, ironic and amusing novel.\\n'\n",
      " '\\n'\n",
      " '\"A Maze of Death\"\\n'\n",
      " 'Noteworthy for its description of a technology-based religion.\\n'\n",
      " '\\n'\n",
      " '\"VALIS\"\\n'\n",
      " 'The schizophrenic hero searches for the hidden mysteries of Gnostic\\n'\n",
      " 'Christianity after reality is fired into his brain by a pink laser beam of\\n'\n",
      " 'unknown but possibly divine origin.  He is accompanied by his dogmatic and\\n'\n",
      " 'dismissively atheist friend and assorted other odd characters.\\n'\n",
      " '\\n'\n",
      " '\"The Divine Invasion\"\\n'\n",
      " 'God invades Earth by making a young woman pregnant as she returns from\\n'\n",
      " 'another star system.  Unfortunately she is terminally ill, and must be\\n'\n",
      " 'assisted by a dead man whose brain is wired to 24-hour easy listening '\n",
      " 'music.\\n'\n",
      " '\\n'\n",
      " 'MARGARET ATWOOD\\n'\n",
      " '\\n'\n",
      " '\"The Handmaid\\'s Tale\"\\n'\n",
      " 'A story based on the premise that the US Congress is mysteriously\\n'\n",
      " 'assassinated, and fundamentalists quickly take charge of the nation to set '\n",
      " 'it\\n'\n",
      " '\"right\" again.  The book is the diary of a woman\\'s life as she tries to '\n",
      " 'live\\n'\n",
      " \"under the new Christian theocracy.  Women's right to own property is \"\n",
      " 'revoked,\\n'\n",
      " 'and their bank accounts are closed; sinful luxuries are outlawed, and the\\n'\n",
      " 'radio is only used for readings from the Bible.  Crimes are punished\\n'\n",
      " 'retroactively: doctors who performed legal abortions in the \"old world\" are\\n'\n",
      " \"hunted down and hanged.  Atwood's writing style is difficult to get used to\\n\"\n",
      " 'at first, but the tale grows more and more chilling as it goes on.\\n'\n",
      " '\\n'\n",
      " 'VARIOUS AUTHORS\\n'\n",
      " '\\n'\n",
      " '\"The Bible\"\\n'\n",
      " 'This somewhat dull and rambling work has often been criticized.  However, '\n",
      " 'it\\n'\n",
      " \"is probably worth reading, if only so that you'll know what all the fuss is\\n\"\n",
      " 'about.  It exists in many different versions, so make sure you get the one\\n'\n",
      " 'true version.\\n'\n",
      " '\\n'\n",
      " '                             Books -- Non-fiction\\n'\n",
      " '\\n'\n",
      " 'PETER DE ROSA\\n'\n",
      " '\\n'\n",
      " '\"Vicars of Christ\", Bantam Press, 1988\\n'\n",
      " 'Although de Rosa seems to be Christian or even Catholic this is a very\\n'\n",
      " 'enlighting history of papal immoralities, adulteries, fallacies etc.\\n'\n",
      " '(German translation: \"Gottes erste Diener. Die dunkle Seite des Papsttums\",\\n'\n",
      " 'Droemer-Knaur, 1989)\\n'\n",
      " '\\n'\n",
      " 'MICHAEL MARTIN\\n'\n",
      " '\\n'\n",
      " '\"Atheism: A Philosophical Justification\", Temple University Press,\\n'\n",
      " ' Philadelphia, USA.\\n'\n",
      " 'A detailed and scholarly justification of atheism.  Contains an outstanding\\n'\n",
      " 'appendix defining terminology and usage in this (necessarily) tendentious\\n'\n",
      " 'area.  Argues both for \"negative atheism\" (i.e. the \"non-belief in the\\n'\n",
      " 'existence of god(s)\") and also for \"positive atheism\" (\"the belief in the\\n'\n",
      " 'non-existence of god(s)\").  Includes great refutations of the most\\n'\n",
      " 'challenging arguments for god; particular attention is paid to refuting\\n'\n",
      " 'contempory theists such as Platinga and Swinburne.\\n'\n",
      " '541 pages. ISBN 0-87722-642-3 (hardcover; paperback also available)\\n'\n",
      " '\\n'\n",
      " '\"The Case Against Christianity\", Temple University Press\\n'\n",
      " 'A comprehensive critique of Christianity, in which he considers\\n'\n",
      " 'the best contemporary defences of Christianity and (ultimately)\\n'\n",
      " 'demonstrates that they are unsupportable and/or incoherent.\\n'\n",
      " '273 pages. ISBN 0-87722-767-5\\n'\n",
      " '\\n'\n",
      " 'JAMES TURNER\\n'\n",
      " '\\n'\n",
      " '\"Without God, Without Creed\", The Johns Hopkins University Press, '\n",
      " 'Baltimore,\\n'\n",
      " ' MD, USA\\n'\n",
      " 'Subtitled \"The Origins of Unbelief in America\".  Examines the way in which\\n'\n",
      " 'unbelief (whether agnostic or atheistic)  became a mainstream alternative\\n'\n",
      " 'world-view.  Focusses on the period 1770-1900, and while considering France\\n'\n",
      " 'and Britain the emphasis is on American, and particularly New England\\n'\n",
      " 'developments.  \"Neither a religious history of secularization or atheism,\\n'\n",
      " 'Without God, Without Creed is, rather, the intellectual history of the fate\\n'\n",
      " 'of a single idea, the belief that God exists.\" \\n'\n",
      " '316 pages. ISBN (hardcover) 0-8018-2494-X (paper) 0-8018-3407-4\\n'\n",
      " '\\n'\n",
      " 'GEORGE SELDES (Editor)\\n'\n",
      " '\\n'\n",
      " '\"The great thoughts\", Ballantine Books, New York, USA\\n'\n",
      " 'A \"dictionary of quotations\" of a different kind, concentrating on '\n",
      " 'statements\\n'\n",
      " \"and writings which, explicitly or implicitly, present the person's \"\n",
      " 'philosophy\\n'\n",
      " 'and world-view.  Includes obscure (and often suppressed) opinions from many\\n'\n",
      " 'people.  For some popular observations, traces the way in which various\\n'\n",
      " 'people expressed and twisted the idea over the centuries.  Quite a number '\n",
      " 'of\\n'\n",
      " 'the quotations are derived from Cardiff\\'s \"What Great Men Think of '\n",
      " 'Religion\"\\n'\n",
      " 'and Noyes\\' \"Views of Religion\".\\n'\n",
      " '490 pages. ISBN (paper) 0-345-29887-X.\\n'\n",
      " '\\n'\n",
      " 'RICHARD SWINBURNE\\n'\n",
      " '\\n'\n",
      " '\"The Existence of God (Revised Edition)\", Clarendon Paperbacks, Oxford\\n'\n",
      " 'This book is the second volume in a trilogy that began with \"The Coherence '\n",
      " 'of\\n'\n",
      " 'Theism\" (1977) and was concluded with \"Faith and Reason\" (1981).  In this\\n'\n",
      " 'work, Swinburne attempts to construct a series of inductive arguments for '\n",
      " 'the\\n'\n",
      " 'existence of God.  His arguments, which are somewhat tendentious and rely\\n'\n",
      " 'upon the imputation of late 20th century western Christian values and\\n'\n",
      " 'aesthetics to a God which is supposedly as simple as can be conceived, were\\n'\n",
      " 'decisively rejected in Mackie\\'s \"The Miracle of Theism\".  In the revised\\n'\n",
      " 'edition of \"The Existence of God\", Swinburne includes an Appendix in which '\n",
      " 'he\\n'\n",
      " 'makes a somewhat incoherent attempt to rebut Mackie.\\n'\n",
      " '\\n'\n",
      " 'J. L. MACKIE\\n'\n",
      " '\\n'\n",
      " '\"The Miracle of Theism\", Oxford\\n'\n",
      " 'This (posthumous) volume contains a comprehensive review of the principal\\n'\n",
      " 'arguments for and against the existence of God.  It ranges from the '\n",
      " 'classical\\n'\n",
      " 'philosophical positions of Descartes, Anselm, Berkeley, Hume et al, through\\n'\n",
      " 'the moral arguments of Newman, Kant and Sidgwick, to the recent '\n",
      " 'restatements\\n'\n",
      " 'of the classical theses by Plantinga and Swinburne.  It also addresses '\n",
      " 'those\\n'\n",
      " 'positions which push the concept of God beyond the realm of the rational,\\n'\n",
      " 'such as those of Kierkegaard, Kung and Philips, as well as \"replacements '\n",
      " 'for\\n'\n",
      " 'God\" such as Lelie\\'s axiarchism.  The book is a delight to read - less\\n'\n",
      " \"formalistic and better written than Martin's works, and refreshingly direct\\n\"\n",
      " 'when compared with the hand-waving of Swinburne.\\n'\n",
      " '\\n'\n",
      " 'JAMES A. HAUGHT\\n'\n",
      " '\\n'\n",
      " '\"Holy Horrors: An Illustrated History of Religious Murder and Madness\",\\n'\n",
      " ' Prometheus Books\\n'\n",
      " 'Looks at religious persecution from ancient times to the present day -- and\\n'\n",
      " 'not only by Christians.\\n'\n",
      " 'Library of Congress Catalog Card Number 89-64079. 1990.\\n'\n",
      " '\\n'\n",
      " 'NORM R. ALLEN, JR.\\n'\n",
      " '\\n'\n",
      " '\"African American Humanism: an Anthology\"\\n'\n",
      " 'See the listing for African Americans for Humanism above.\\n'\n",
      " '\\n'\n",
      " 'GORDON STEIN\\n'\n",
      " '\\n'\n",
      " '\"An Anthology of Atheism and Rationalism\", Prometheus Books\\n'\n",
      " \"An anthology covering a wide range of subjects, including 'The Devil, Evil\\n\"\n",
      " \"and Morality' and 'The History of Freethought'.  Comprehensive \"\n",
      " 'bibliography.\\n'\n",
      " '\\n'\n",
      " 'EDMUND D. COHEN\\n'\n",
      " '\\n'\n",
      " '\"The Mind of The Bible-Believer\", Prometheus Books\\n'\n",
      " 'A study of why people become Christian fundamentalists, and what effect it\\n'\n",
      " 'has on them.\\n'\n",
      " '\\n'\n",
      " '                                Net Resources\\n'\n",
      " '\\n'\n",
      " \"There's a small mail-based archive server at mantis.co.uk which carries\\n\"\n",
      " 'archives of old alt.atheism.moderated articles and assorted other files.  '\n",
      " 'For\\n'\n",
      " 'more information, send mail to archive-server@mantis.co.uk saying\\n'\n",
      " '\\n'\n",
      " '   help\\n'\n",
      " '   send atheism/index\\n'\n",
      " '\\n'\n",
      " 'and it will mail back a reply.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'mathew\\n'\n",
      " 'Ã¿\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(type(X))\n",
    "pprint(type(X[0]))\n",
    "pprint(type(X[0][0]))\n",
    "pprint(type(X[0][1]))\n",
    "pprint(type(Y))\n",
    "pprint(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split using Regex Is Better than working with normal split function\n",
    "import re\n",
    "sample_string = \"Hello there!, this Aryaveer., and currently learning data science and working Aryaveer on this project.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello',\n",
      " 'there',\n",
      " 'this',\n",
      " 'Aryaveer',\n",
      " 'and',\n",
      " 'currently',\n",
      " 'learning',\n",
      " 'data',\n",
      " 'science',\n",
      " 'and',\n",
      " 'working',\n",
      " 'Aryaveer',\n",
      " 'on',\n",
      " 'this',\n",
      " 'project',\n",
      " '']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Identifiers:\n",
    "\\d any number\n",
    "\\D anything but a number\n",
    "\\s space\n",
    "\\S anything but space\n",
    "\\w any character\n",
    "\\W any but Character [^a-zA-Z0-9_]\n",
    ". = any char, except newline\n",
    "\\b the white space around words\n",
    "\\. a period\n",
    "Modifiers:\n",
    "{1,3} we're expection 1 3 \\d{1-3}\n",
    "+ Match 1 or more\n",
    "? match 0 or 1\n",
    "* Match 0 or more\n",
    "$ match the end of string\n",
    "^ matching the beggining of a string\n",
    "| either or \n",
    "[] range or variance\n",
    "\n",
    "White Space Characters:\n",
    "\\n new line\n",
    "\\s space\n",
    "\\t tab\n",
    "\\e escape\n",
    "\\f form feed\n",
    "\\r return \n",
    "\"\"\"\n",
    "pprint(re.split(r'\\W+',sample_string)) # '\\W'  It matches any non-word character and is equivalent to [^a-zA-Z0-9_]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dictionary as explained above\n",
    "dictionary = dict()\n",
    "for x in range(len(x_train)):\n",
    "# X[] was splitted into x_train, but X[0] is name of document \n",
    "# and X[1] is the text so we will iterate over X[1]\n",
    "    currentWord = x_train[x][1].lower()\n",
    "    # splitting text into words\n",
    "    strippedList = re.split(r'\\W+', currentWord)\n",
    "    for word in strippedList:\n",
    "        #skip stopword, alphanumeric, punctuations or word with length <=2\n",
    "        if not (word.isalpha()) or (word in stop_words) or len(word)<=2:\n",
    "            continue\n",
    "        else:\n",
    "            if word in dictionary:\n",
    "                dictionary[word] +=1\n",
    "            else:\n",
    "                dictionary[word] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101789"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cmu', 70248),\n",
       " ('com', 67306),\n",
       " ('news', 46094),\n",
       " ('srv', 43408),\n",
       " ('cantaloupe', 34952),\n",
       " ('net', 34260),\n",
       " ('message', 29489),\n",
       " ('subject', 28955),\n",
       " ('lines', 27981),\n",
       " ('date', 27839),\n",
       " ('apr', 27436),\n",
       " ('newsgroups', 27342),\n",
       " ('path', 27270),\n",
       " ('organization', 26592),\n",
       " ('state', 25025),\n",
       " ('gmt', 23932),\n",
       " ('would', 21446),\n",
       " ('ohio', 21101),\n",
       " ('one', 20932)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting the dictionary\n",
    "sorted_dic = sorted(dictionary.items(), key = operator.itemgetter(1), reverse =  True)\n",
    "sorted_dic[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101789"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Word Vs. Frequency\n",
    "#On basis of graph we can decide the number of features we want to take\n",
    "Words=list()\n",
    "Frequency = list()\n",
    "for x in range(len(sorted_dic)):\n",
    "    Words.append(x)\n",
    "    Frequency.append(sorted_dic[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Words, Frequency)\n",
    "plt.axis([0,8000,1,5000])\n",
    "plt.grid()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cmu',\n",
       " 'com',\n",
       " 'news',\n",
       " 'srv',\n",
       " 'cantaloupe',\n",
       " 'net',\n",
       " 'message',\n",
       " 'subject',\n",
       " 'lines']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Considering Top 2500 Words with max frequency as our features\n",
    "featureColumns = [sorted_dic[x][0] for x in range(0,2500)]\n",
    "featureColumns[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 26795,\n",
       " ('38282',\n",
       "  \"Newsgroups: comp.graphics\\nPath: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!zaphod.mps.ohio-state.edu!uwm.edu!caen!batcomputer!ghost.dsi.unimi.it!rosa\\nFrom: rosa@ghost.dsi.unimi.it (massimo rossi)\\nSubject: 3d studio works changes!!!!\\nOrganization: Computer Science Dep. - Milan University\\nDate: Thu, 15 Apr 1993 08:18:06 GMT\\nMessage-ID: <1993Apr15.081806.7019@ghost.dsi.unimi.it>\\nLines: 28\\n\\n hi guys\\n like all people in this group i'm a fans of fractal and render sw\\n my favourite are fractint pov & 3dstudio 2.0 \\n now listen my ideas\\n i'have just starting now to be able to use 3dstudio quite well\\n so i'm simulating a full animation of a f1 grand prix\\n unfortanatly just some lap(10?)\\n i' m very interested about all kind of .prj .3ds and so on\\n concerning about cars or parts of its (motors wheel ...)\\n (dxf are good enough)\\n does anyone have object to give me to complete my hard animation\\n\\n\\n anyway any exchanges about object material project will\\n be VERY APRECIATE!!!!!\\n\\n is there a ftp site where I can find its?\\n\\n i' m looking for .pov files too\\n (i 'm interested about cpu time comparision rendering images on\\n pov & 3dstusio)\\n\\n thank to all\\n\\n\\n email me at rosa@ghost.sm.dsi.unimi.it\\n\\n\\n\"))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[1]), len(x_train) , x_train[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making x_train dataset\n",
    "#No. of rows is equivalent to rows in x_train, and column is equal to \n",
    "# length of featureColumns\n",
    "# we will be creating a x_train_dataset matrix of with rows as documents like d1, d2,...\n",
    "# and columns as features like edu, cmu ...\n",
    "# any x_train_dataset[something][something] will denote\n",
    "# how many times does the any feature like edu appeared in the document like\n",
    "# d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dataset = np.zeros([len(x_train),len(featureColumns)],int) # int denotes datatype of any block\n",
    "x_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    words = x_train[i][1].lower()\n",
    "    word = re.split(r'\\W+', words)\n",
    "     # We will add the frequency corresponding to that word only which is\n",
    "     # in our featureColumns\n",
    "    for j in word:\n",
    "        if j in featureColumns:\n",
    "            x_train_dataset[i][featureColumns.index(j)]+=1 # .index gives index of that element\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26795"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  3  4 ...  0  0  0]\n",
      " [ 4  1  0 ...  0  0  0]\n",
      " [ 7  3  1 ...  0  0  0]\n",
      " ...\n",
      " [10  2  0 ...  0  0  0]\n",
      " [ 6  4  6 ...  0  0  0]\n",
      " [ 9  2  1 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making x_test dataset\n",
    "# No. of rows is equivalent to rows in x_test, and column is equal to length to answer1(feature list)\n",
    "x_test_dataset = np.zeros([len(x_test), len(featureColumns)], int)\n",
    "for i in range(len(x_test)):\n",
    "    words = x_test[i][1].lower()\n",
    "    word = re.split(r'\\W+', words)\n",
    "    # Iterating over each word\n",
    "    for j in word:\n",
    "        if j in featureColumns:\n",
    "            x_test_dataset[i][featureColumns.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  3  4 ...  0  0  0]\n",
      " [ 4  1  0 ...  0  0  0]\n",
      " [ 7  3  1 ...  0  0  0]\n",
      " ...\n",
      " [10  2  0 ...  0  0  0]\n",
      " [ 6  4  6 ...  0  0  0]\n",
      " [ 9  2  1 ...  0  0  0]]\n",
      "=========================\n",
      "[[ 8  3  0 ...  0  0  0]\n",
      " [ 1  1  0 ...  0  0  0]\n",
      " [ 7  1  2 ...  0  0  0]\n",
      " ...\n",
      " [ 5  5  5 ...  0  0  0]\n",
      " [14  2  0 ...  0  0  0]\n",
      " [ 2  1  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_dataset)\n",
    "print(\"=========================\")\n",
    "print(x_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_dataset,y_train)\n",
    "y_pred = clf.predict(x_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training Dataset:  0.8991602910990857\n",
      "Score on test Dataset:  0.8843851806955072\n"
     ]
    }
   ],
   "source": [
    "print(\"Score on training Dataset: \", clf.score(x_train_dataset, y_train))\n",
    "print(\"Score on test Dataset: \", clf.score(x_test_dataset,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[568   1   0   0   1   0   0   4   7   0   0   0   2   1   1   4   0   2\n",
      "    0  83]\n",
      " [  0 555  30  26  28  20  16   2   2   0   0   0   5   2   2   0   0   0\n",
      "    0   0]\n",
      " [  0   9 544  37   9  44   7   1   0   0   0   0   4   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   8  15 529  60   1  12   0   1   0   0   1  18   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   8   2  22 631   0   9   0   0   0   0   0   6   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  27  25   8  10 558   3   2   0   0   0   2   3   0   3   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   6   3   0 660   6   2   1   1   0   7   0   0   0   2   0\n",
      "    0   0]\n",
      " [  0   2   0   0   3   2  24 618   7   1   3   0  12   0   2   0   1   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0  10  14 646   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0  11   4   6 602  21   0   0   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   2   6   3   2  20 616   0   0   0   1   0   0   0\n",
      "    1   0]\n",
      " [  0   1   1   0   1   5   0   1   0   0   0 627   7   5   1   0   1   0\n",
      "    0   0]\n",
      " [  0   3   0  11  17   0  11  12   2   0   1   0 608   6   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0   1   6   5   9   4   9   2   1   0  10 581   3   0   0   0\n",
      "    1   0]\n",
      " [  0   5   0   1   3   2   3   0   2   8   2   0  13   2 627   0   1   0\n",
      "    3   1]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0 642   0   4\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   1   1   5   0   0   7   0   0   3   0 601   0\n",
      "   27  13]\n",
      " [  0   0   0   0   5   0   5   1   1   0   2   0   1   0   0   0   7 579\n",
      "   30   3]\n",
      " [  0   1   0   0   0   0   4   1   0   0   1   7   1   1   8   2  66  41\n",
      "  469  75]\n",
      " [120   1   0   0   0   3   5   1   0   0   1   0   0   5   0  24  29   3\n",
      "   36 412]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.83      0.84      0.83       674\n",
      "           comp.graphics       0.89      0.81      0.85       688\n",
      " comp.os.ms-windows.misc       0.88      0.83      0.85       656\n",
      "comp.sys.ibm.pc.hardware       0.82      0.82      0.82       645\n",
      "   comp.sys.mac.hardware       0.81      0.93      0.87       678\n",
      "          comp.windows.x       0.87      0.87      0.87       641\n",
      "            misc.forsale       0.83      0.96      0.89       689\n",
      "               rec.autos       0.92      0.91      0.91       676\n",
      "         rec.motorcycles       0.93      0.96      0.95       670\n",
      "      rec.sport.baseball       0.95      0.93      0.94       646\n",
      "        rec.sport.hockey       0.95      0.95      0.95       651\n",
      "               sci.crypt       0.97      0.96      0.97       650\n",
      "         sci.electronics       0.87      0.91      0.89       671\n",
      "                 sci.med       0.96      0.92      0.94       634\n",
      "               sci.space       0.96      0.93      0.95       673\n",
      "  soc.religion.christian       0.96      0.99      0.97       647\n",
      "      talk.politics.guns       0.85      0.91      0.88       659\n",
      "   talk.politics.mideast       0.92      0.91      0.92       634\n",
      "      talk.politics.misc       0.83      0.69      0.75       677\n",
      "      talk.religion.misc       0.70      0.64      0.67       640\n",
      "\n",
      "                accuracy                           0.88     13199\n",
      "               macro avg       0.88      0.88      0.88     13199\n",
      "            weighted avg       0.88      0.88      0.88     13199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Implementation of Naive Baye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dictionary for implementing Naive Baye's\n",
    "def fit(x_train_dataset,y_train):\n",
    "    count={}\n",
    "    total_word=0\n",
    "    y_train=np.array(y_train)\n",
    "    #Total no. of document is calculated\n",
    "    count[\"total_doc\"]=len(y_train)\n",
    "    classes=set(y_train)\n",
    "    for i in classes:\n",
    "        temp=0\n",
    "        #selecting x_train corresponding to class present in y_train\n",
    "        x_train_with_i=x_train_dataset[y_train==i]\n",
    "        #finding length of data with category corresponding to i \n",
    "        temp2=x_train_with_i.shape[0]\n",
    "        count[i]={}\n",
    "        #Iterating over answer1(actual feature list)\n",
    "        for feature in featureColumns:\n",
    "            #Calculating total word in feature\n",
    "            l=(x_train_with_i[:,featureColumns.index(feature)]).sum()\n",
    "            count[i][feature]=l\n",
    "            temp+=l\n",
    "        #Total word in that class\n",
    "        count[i][\"word_in_class\"]=temp\n",
    "        #Length of data with y_train belonging to specific class\n",
    "        count[i][\"length\"]=temp2\n",
    "        \n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(x_test,dic,classes):\n",
    "    prob=np.log(dic[classes][\"length\"])-np.log(dic[\"total_doc\"])\n",
    "    feature=list(dic[classes].keys())\n",
    "    #-2 is done becuase there will be \"length\" and \"word in class\" present in feature. \n",
    "    for j in range (len(feature)-2):\n",
    "        xj=x_test[j]\n",
    "        #If frequency is 0, we will not consider it\n",
    "        if xj==0:\n",
    "            current_prob=0\n",
    "        else:\n",
    "            #Extra addition part is Laplace correction\n",
    "            num=dic[classes][feature[j]]+1\n",
    "            den=dic[classes][\"word_in_class\"]+len(dic[classes].keys())-2\n",
    "            current_prob=np.log(num)-np.log(den)\n",
    "        prob+=current_prob\n",
    "    return prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best_class or probable answer will be returned from here\n",
    "def predict_for_single(x_test,dic):\n",
    "    first_run=True\n",
    "    classes=dic.keys()\n",
    "    for i in classes:\n",
    "        if i==\"total_doc\":\n",
    "            continue\n",
    "        prob=probability(x_test,dic,i)\n",
    "        if first_run or prob>best_prob:\n",
    "            best_prob=prob\n",
    "            first_run=False\n",
    "            best_class=i\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_(x_test,dic):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        y_pred.append(predict_for_single(x,dic))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_test,y_pred):\n",
    "        count = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == y_test[i]:\n",
    "                count+=1\n",
    "        return count/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-220-42c17f38c6f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#This cell will take time to execute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-218-818e8d463b31>\u001b[0m in \u001b[0;36mpredict_\u001b[1;34m(x_test, dic)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_for_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-217-242850941572>\u001b[0m in \u001b[0;36mpredict_for_single\u001b[1;34m(x_test, dic)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"total_doc\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mprob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfirst_run\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mbest_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mbest_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-216-8dc9253a6b36>\u001b[0m in \u001b[0;36mprobability\u001b[1;34m(x_test, dic, classes)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"word_in_class\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mcurrent_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mprob\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mcurrent_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#This cell will take time to execute\n",
    "dictionary=fit(x_train_dataset,y_train)\n",
    "y_pred=predict_(x_test_dataset,dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score on testing_data:\",score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULT:\n",
    "\n",
    "We have performed text-classification both by sklearn and self implementation.\n",
    "\n",
    "We found out that sklearn gave score of 0.86 on testing_data,whereas self implemented classifier gave 0.87 on testing data,which is very close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
