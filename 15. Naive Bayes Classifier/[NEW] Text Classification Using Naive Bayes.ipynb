{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Classification mean a text can be classified whether it is spam or not,\n",
    "classifing it into some category of text like sports, politics etc..\n",
    "\n",
    "How it will work :\n",
    "let say we a text on length 'n', with lots of stopwords like (a, the, they etc) and will remove this stopwords then move to next step.\n",
    "find top important word we want to use as our features, let say we n words from $w_{1}$ to $w_{n}$ \n",
    "the way we will convert input data input features(w1...wn)(columns)\n",
    "for each training data points(rows) we will have frequency of that word \n",
    "\n",
    "Y column also with spam or nonspam\n",
    "\n",
    "P(cricket |  y = a1) = count(Cricket in a1 documents)/count(total words in a1 documents)\n",
    "\n",
    "In mathematical form with laplace correction:\n",
    "$\\frac{N_{a_{1}}^{cricket}+1}{N_{a_{1}}+n}$\n",
    "where 'n' is the size of vocab \n",
    "\n",
    "this formula is called \"MULTINOMIAL NAIVE BAYES\"\n",
    "\n",
    "inbuilt Multinomial Naive bayes will perform very bad on iris data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
